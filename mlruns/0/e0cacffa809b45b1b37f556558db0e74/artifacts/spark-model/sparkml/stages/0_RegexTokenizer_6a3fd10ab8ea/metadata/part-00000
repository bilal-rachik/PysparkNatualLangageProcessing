{"class":"org.apache.spark.ml.feature.RegexTokenizer","timestamp":1561650870274,"sparkVersion":"2.4.3","uid":"RegexTokenizer_6a3fd10ab8ea","paramMap":{"pattern":"[^a-z_]","minTokenLength":3,"inputCol":"lib1","gaps":true,"outputCol":"tokenizedDescr"},"defaultParamMap":{"pattern":"\\s+","minTokenLength":1,"gaps":true,"toLowercase":true,"outputCol":"RegexTokenizer_6a3fd10ab8ea__output"}}
