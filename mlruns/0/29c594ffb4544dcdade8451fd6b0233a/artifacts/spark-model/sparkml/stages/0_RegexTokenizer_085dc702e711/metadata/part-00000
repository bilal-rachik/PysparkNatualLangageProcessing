{"class":"org.apache.spark.ml.feature.RegexTokenizer","timestamp":1561731529373,"sparkVersion":"2.4.3","uid":"RegexTokenizer_085dc702e711","paramMap":{"outputCol":"tokenizedDescr","gaps":true,"inputCol":"lib1","minTokenLength":3,"pattern":"[^a-z_]"},"defaultParamMap":{"toLowercase":true,"outputCol":"RegexTokenizer_085dc702e711__output","gaps":true,"minTokenLength":1,"pattern":"\\s+"}}
